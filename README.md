# AI-Builders-Bootcamp-7
Code repository for AI Builders Bootcamp #7

Past Cohorts: [Cohort 1](https://github.com/ShawhinT/AI-Builders-Bootcamp-1) | [Cohort 2](https://github.com/ShawhinT/AI-Builders-Bootcamp-2) | [Cohort 3](https://github.com/ShawhinT/AI-Builders-Bootcamp-3) | [Cohort 4](https://github.com/ShawhinT/AI-Builders-Bootcamp-4) | [Cohort 5](https://github.com/ShawhinT/AI-Builders-Bootcamp-5) | [Cohort 6](https://github.com/ShawhinT/AI-Builders-Bootcamp-6)

Course homepage on Maven: https://maven.com/shaw-talebi/ai-builders-bootcamp

## Session 1: Introduction, Software 1.0
Getting started with AI and building with LLM-powered tools.

Examples:
- [Scraping AI job board](https://github.com/ShawhinT/AI-Builders-Bootcamp-7/blob/main/session-1/example_1-scrape_job_board.ipynb)
- [Vibe Coding Data Dashboard](https://github.com/ShawhinT/AI-Builders-Bootcamp-7/blob/main/session-1/example_2-job_dashboard.py)

## Session 2: LLMs, Prompt Engineering
Here, we begin building AI systems with LLMs. Unlike machine learning, we don't need datasets to get started.

Examples:
- [Research paper summarizer](https://github.com/ShawhinT/AI-Builders-Bootcamp-7/blob/main/session-2/example_1-paper_summarizer.ipynb)
- [Lead Scoring](https://github.com/ShawhinT/AI-Builders-Bootcamp-7/blob/main/session-2/example_2-lead_scoring.ipynb)

## Session 3: RAG, Text Embeddings
Prompting LLMs ChatGPT-style only scratches the surface of what we can use modern language models for. We can also leverage RAG to improve model performance and text embeddings to make text computable.

Examples:
- [RAG with LlamaIndex](https://github.com/ShawhinT/AI-Builders-Bootcamp-7/blob/main/session-3/example_2-rag_with_llamaindex.ipynb)
- [Analyzing Unstructured Survey Data](https://github.com/ShawhinT/AI-Builders-Bootcamp-7/blob/main/session-3/example_1-unstructured_survey_analysis.ipynb)

## Session 4: Tool Use, AI Agents
While prompting LLMs and automatically giving them relevant context can take us far, they still involve a traditional approach to software development. Namely, developers break down tasks into steps and translate them into code + LLM calls. 

Agents present a new way of thinking about software. Rather than explicitly defining rules and business logic, agents involve giving LLMs the tools they need to solve problems.

Examples:
- [YouTube Agent](https://github.com/ShawhinT/AI-Builders-Bootcamp-7/blob/main/session-4/example_1-youtube_agent.ipynb)
- [Notion MCP Agent](https://github.com/ShawhinT/AI-Builders-Bootcamp-7/blob/main/session-4/example_2-notion_mcp_agent.ipynb)
- [Upwork Profile Rewriter (in a loop)](https://github.com/ShawhinT/AI-Builders-Bootcamp-7/blob/main/session-4/example_3-profile_rewriter_loop.ipynb)

## Session 5: Fine-tuning
Although LLMs can solve a wide range of problems out of the box, there are situations where more model customization is required. This can be achieved through model fine-tuning, which involves adapting a model to a particular use case through additional training.

Examples:
- [Fine-tuning a LinkedIn Post Writer](https://github.com/ShawhinT/AI-Builders-Bootcamp-7/tree/main/session-5/example-1)
- [Fine-tuning Text Embeddings on AI Jobs](https://github.com/ShawhinT/AI-Builders-Bootcamp-7/tree/main/session-5/example-2)
