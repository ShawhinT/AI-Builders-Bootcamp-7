{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11c076dd-4e32-431c-9793-e0784197e3d1",
   "metadata": {},
   "source": [
    "# Fine-tuning GPT-4.1 to Write LinkedIn Posts (in my style)\n",
    "## ABB #7 - Session 5\n",
    "\n",
    "Code authored by: Shaw Talebi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7812b7-9bb9-47da-8116-f6af553e18c5",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8369ae91-d925-4ed1-9a85-32fb8e64a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f67fe3b-4926-4ece-b3d7-7e77fbf73a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sk from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# connect to openai API\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed5e0ce-bc78-48d6-9f80-dffef543dc8e",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1044c3-584c-43cb-b1ee-611cd18075a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def clean_post(text):\n",
    "    # Split into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Remove leading/trailing quotes and whitespace, and filter out empty lines\n",
    "    cleaned_lines = [line.strip().strip('\"') for line in lines]\n",
    "    # Join back into a single string\n",
    "    return '\\n'.join(cleaned_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b592333-9f9a-46dd-9bb6-e8683100ee06",
   "metadata": {},
   "source": [
    "## Step 1: Input-output Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b2a2d-75c7-4913-b603-93127ece77fc",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc4f088-1331-4de4-a252-c60210479042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('data/LI_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8d57fd-6e73-4532-90c3-424c63ad08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column names\n",
    "df.columns = ['date', 'link', 'post', 'idea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd86024c-63d6-45ec-bf83-06e401db9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dtypes\n",
    "df = df.astype({\n",
    "    'date': str,\n",
    "    'link': str,\n",
    "    'post': str,\n",
    "    'idea': str\n",
    "})\n",
    "\n",
    "# Convert date column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "093d3d18-a9b4-4d1f-9285-bbfe6a310b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index\n",
    "df = df.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796fdec9-00bd-4567-a1bf-0fe3c5e594a6",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b1ed5cc-0b33-47ca-a4cd-1be0a4b30b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process posts\n",
    "df['post'] = df['post'].apply(clean_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc59612-8b88-4a51-bb5b-a30ef8273f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace idea with first line of post\n",
    "df['idea'] = df['post'].str.split('\\n').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f073c9e-0f1c-4910-8beb-5866a32bfc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2228abb1-a726-4d55-8eb3-d155135caa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with posts less than 3 lines\n",
    "df = df[df['post'].str.split('\\n').str.len() >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d1648b4-60a2-40d9-887f-e195352a16a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b7d17-afd2-4409-bda7-c4e2ab6c5e1f",
   "metadata": {},
   "source": [
    "## Step 2: Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd558b-b292-4582-a965-04ebeb46c403",
   "metadata": {},
   "source": [
    "### Create training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6ed7112-b939-41d4-9fc2-077c9c85229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct training examples\n",
    "example_list = []\n",
    "\n",
    "system_prompt = \"\"\"# LinkedIn Ghostwriter\n",
    "\n",
    "You are a LinkedIn Ghostwriter for Shaw Talebi, an AI educator and entrepreneur.\n",
    "\n",
    "Given a post idea's first line from the user, generate a post in Shaw's unique style.\n",
    "\n",
    "Include the following in each post:\n",
    "- A compelling opening 1-2 lines that hooks the reader\n",
    "- Copy that expands upon the idea in valuable way\n",
    "- A call to action or share relevant content\n",
    "- Don't use hashtags\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(df)):    \n",
    "    system_dict = {\"role\": \"system\", \"content\": system_prompt}\n",
    "    user_dict = {\"role\": \"user\", \"content\": df['idea'].iloc[i]}\n",
    "    assistant_dict = {\"role\": \"assistant\", \"content\": df['post'].iloc[i]}\n",
    "    \n",
    "    messages_list = [system_dict, user_dict, assistant_dict]\n",
    "    \n",
    "    example_list.append({\"messages\": messages_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c847ac6-89de-413f-a7c4-854e9a514658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# LinkedIn Ghostwriter\n",
      "\n",
      "You are a LinkedIn Ghostwriter for Shaw Talebi, an AI educator and entrepreneur.\n",
      "\n",
      "Given a post idea's first line from the user, generate a post in Shaw's unique style.\n",
      "\n",
      "Include the following in each post:\n",
      "- A compelling opening 1-2 lines that hooks the reader\n",
      "- Copy that expands upon the idea in valuable way\n",
      "- A call to action or share relevant content\n",
      "- Don't use hashtags\n",
      "\n",
      "---\n",
      "LLM capabilities are doubling every 7 monthsâ€¦\n",
      "---\n",
      "LLM capabilities are doubling every 7 monthsâ€¦\n",
      "\n",
      "Hereâ€™s the most important LLM benchmark Iâ€™ve come across ðŸ‘‡ \n",
      "\n",
      "A couple of months ago, the team at METR released a new AI benchmark.\n",
      "\n",
      "Rather than evaluating AI systems in terms of accuracy on well-known datasets or artificial tasks, it evaluates them on real-world tasks measured in average human task completion time.\n",
      "\n",
      "In other words, they took 170 tasks, measured how long it typically takes a human to do each, then evaluated whether an AI system could do each with >50% accuracy.\n",
      "\n",
      "Current models can easily handle â€œ1-hour tasks,â€ e.g. write simple ETL scripts, set up a software package.\n",
      "\n",
      "However, the most notable finding was that these capabilities have been accelerating over the past 6 years, approximately doubling every 7 months.\n",
      "\n",
      "Extrapolating out, this means that models will be able to doâ€¦\n",
      "â€¦ 1-day tasks in 2026\n",
      "â€¦ 1-week tasks in 2027\n",
      "â€¦ 1-month tasks in 2029 ðŸ˜³ \n",
      "\n",
      "Itâ€™s hard to imagine what the consequences will be if LLMs can do a monthâ€™s worth of work!\n",
      "\n",
      "What do you think 2029 will look like?\n",
      "\n",
      "--\n",
      "â™»ï¸ If you liked this post, repost it!\n"
     ]
    }
   ],
   "source": [
    "print(example_list[0]['messages'][0]['content'])\n",
    "print(\"---\")\n",
    "print(example_list[0]['messages'][1]['content'])\n",
    "print(\"---\")\n",
    "print(example_list[0]['messages'][2]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daa80954-4589-4850-8b69-b2427828247b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39301b03-69be-4f2c-b7fd-44e17a22be2a",
   "metadata": {},
   "source": [
    "## Step 3: Create train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d43a2f6-b5b8-40c6-92c9-f4ac00c35643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly pick out validation examples\n",
    "num_examples = 68\n",
    "validation_index_list = random.sample(range(0, len(example_list)-1), num_examples)\n",
    "validation_data_list = [example_list[index] for index in validation_index_list]\n",
    "\n",
    "for example in validation_data_list:\n",
    "    example_list.remove(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bf38b30-6c4e-4956-96e6-b7bc5f92423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "print(len(example_list))\n",
    "print(len(validation_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09999da1-e0a4-4bee-949d-c31006dad700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write examples to file\n",
    "with open('data/train-data.jsonl', 'w') as train_file:\n",
    "    for example in example_list:\n",
    "        json.dump(example, train_file)\n",
    "        train_file.write('\\n')\n",
    "\n",
    "with open('data/valid-data.jsonl', 'w') as valid_file:\n",
    "    for example in validation_data_list:\n",
    "        json.dump(example, valid_file)\n",
    "        valid_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1eb41d-f61b-493e-b2dc-1abc458ba9a4",
   "metadata": {},
   "source": [
    "### Upload data to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f3ff2b6-7530-48f9-837b-86000d7f72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = client.files.create(\n",
    "  file = open(\"data/train-data.jsonl\", \"rb\"),\n",
    "  purpose = \"fine-tune\"\n",
    ")\n",
    "\n",
    "valid_file = client.files.create(\n",
    "  file = open(\"data/valid-data.jsonl\", \"rb\"),\n",
    "  purpose = \"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d753629d-45e5-4d0f-b0bd-0bef1c51062c",
   "metadata": {},
   "source": [
    "## Step 4: Fine-tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88425464-a1ec-4230-a025-19f9a848a73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-f18vbmVebAdhTwi1RUFEjhs6', created_at=1763077224, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.25, n_epochs=3), model='gpt-4.1-mini-2025-04-14', object='fine_tuning.job', organization_id='org-KjWERyZ9WLUqIdrdMeJh4zC0', result_files=[], seed=372366926, status='validating_files', trained_tokens=None, training_file='file-7crdcax2n2CgHmLbJwi5py', validation_file='file-BMxFq3xhT9LiWeBgDhx1c2', estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size=1, learning_rate_multiplier=1.25, n_epochs=3))), user_provided_suffix='LI-post-writer', usage_metrics=None, shared_with_openai=False, eval_id=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "    training_file = train_file.id,\n",
    "    validation_file = valid_file.id,\n",
    "    suffix = \"LI-post-writer\",\n",
    "    model = \"gpt-4.1-mini-2025-04-14\",\n",
    "    method={\n",
    "    \"type\": \"supervised\",\n",
    "    \"supervised\": {\n",
    "      \"hyperparameters\": {\n",
    "        \"n_epochs\": 3,\n",
    "        \"learning_rate_multiplier\": 1.25,\n",
    "        \"batch_size\": 1,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c650e56-77a0-4a76-a52e-6d9194fb6278",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd26bc6e-7bee-45f2-88a2-e419de0fb762",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_post(system_prompt, model_name, idea):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": idea}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f5b4455-b219-4fee-95ec-d99ab052acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idea = \"5 things I learned from 5 years on YouTube\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9558b2-b4e5-47aa-8377-ef8661c297a7",
   "metadata": {},
   "source": [
    "#### GPT-4.1-mini (no fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17be2632-d9ee-44b9-9569-19e274f0709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Purpose and Audience  \n",
      "- Purpose: Share practical lessons learned from five years of creating content on YouTube.  \n",
      "- Audience: Content creators, entrepreneurs, and anyone interested in building an online presence.\n",
      "\n",
      "Step 2: Wireframe  \n",
      "- Hook: A clear, curiosity-driven statement about lessons from five years on YouTube.  \n",
      "- Body: List five specific, practical things learned, each with a brief explanation.  \n",
      "- CTA: Ask readers to share their own practical insights or tools for content creation.\n",
      "\n",
      "Step 3: Body (Meat)  \n",
      "- 1) Consistency in publishing builds audience over time.  \n",
      "- 2) Content quality improves with practice and feedback.  \n",
      "- 3) Engaging with your community helps sustain growth.  \n",
      "- 4) Analytics guide you to what works and what doesnâ€™t.  \n",
      "- 5) Experimenting with formats and styles is essential to find your voice.\n",
      "\n",
      "Step 4: CTA  \n",
      "- What practical lessons have you learned from creating content over time?\n",
      "\n",
      "Step 5: Hook Directions  \n",
      "- [Userâ€™s own phrasing] â€œ5 things I learned from 5 years on YouTubeâ€  \n",
      "- [Problem/solution] â€œMost creators struggle to sustain YouTubeâ€”here are 5 lessons from 5 yearsâ€  \n",
      "- [Results/outcomes] â€œHere are 5 practical lessons from 5 years of content creation on YouTubeâ€  \n",
      "- [Beginner-to-expert clarity] â€œWhat 5 years on YouTube taught me about building an audienceâ€  \n",
      "\n",
      "Step 5B: Notes on directions  \n",
      "- Userâ€™s phrasing is straightforward and clear.  \n",
      "- Problem/solution adds context but may be less direct.  \n",
      "- Results/outcomes is promising but overlaps with user phrasing.  \n",
      "- Beginner-to-expert frames the lessons as applicable for growth.\n",
      "\n",
      "Step 5C: Choose strongest direction  \n",
      "- Use userâ€™s own phrasing for clarity and directness.\n",
      "\n",
      "Step 6: Draft full post  \n",
      "5 things I learned from 5 years on YouTube\n",
      "\n",
      "After five years of creating videos, here are five practical lessons that helped me improve and sustain growth:\n",
      "\n",
      "1) Consistency matters. Posting regularly builds and retains an audience.  \n",
      "2) Quality improves with practice and feedback. Donâ€™t expect perfection at the start.  \n",
      "3) Engage with your viewers. Responding to comments and questions keeps people coming back.  \n",
      "4) Use analytics to understand what content resonates and adjust accordingly.  \n",
      "5) Experiment with different formats and styles to find what works best for you.\n",
      "\n",
      "What practical lessons have you learned from creating content over time?\n",
      "\n",
      "Step 7: Review  \n",
      "- One em dash used (in the hook if any, currently none, so no em dash needed).  \n",
      "- Literal, clear language.  \n",
      "- No clichÃ©s or motivational language.  \n",
      "- Clear, practical lessons with actionable hints.  \n",
      "- CTA is focused and relevant.\n",
      "\n",
      "Step 8: Final post below.\n",
      "\n",
      "---\n",
      "\n",
      "5 things I learned from 5 years on YouTube\n",
      "\n",
      "After five years of creating videos, here are five practical lessons that helped me improve and sustain growth:\n",
      "\n",
      "1) Consistency matters. Posting regularly builds and retains an audience.  \n",
      "2) Quality improves with practice and feedback. Donâ€™t expect perfection at the start.  \n",
      "3) Engage with your viewers. Responding to comments and questions keeps people coming back.  \n",
      "4) Use analytics to understand what content resonates and adjust accordingly.  \n",
      "5) Experiment with different formats and styles to find what works best for you.\n",
      "\n",
      "What practical lessons have you learned from creating content over time?\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-4.1-mini-2025-04-14\"\n",
    "# model_name = \"gpt-4.1-2025-04-14\"\n",
    "\n",
    "# read (long) system prompt\n",
    "with open(\"prompts/linkedin-prompt.md\", \"r\") as file:\n",
    "    system_prompt_long = file.read()\n",
    "\n",
    "print(generate_post(system_prompt_long, model_name, idea))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c47fe79-e8d8-4e3f-80e6-5eaa4207819d",
   "metadata": {},
   "source": [
    "#### GPT-4.1-mini (fine-tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cc2e3fb-a692-47eb-87e8-4e9ae788f0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 things I learned from 5 years on YouTube\n",
      "\n",
      "1) Use a \"hook\" - get to the point quickly and don't waste people's time\n",
      "2) Use visuals - I can't explain something in 30 seconds using words alone\n",
      "3) Repurpose content - I've turned 1 YouTube video into 10 pieces of content\n",
      "4) Content > Camera equipment - I can easily outproduce any competition with a better idea\n",
      "5) Don't fight the algorithm - post more and post consistently \n",
      "\n",
      "You can see how I apply these lessons in my latest video: https://lnkd.in/gM6qG2tV\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ft:gpt-4.1-mini-2025-04-14:shawhin-talebi-ventures-llc:li-post-writer:CaR7nerw\"\n",
    "\n",
    "# print(system_prompt, \"\\n--\")\n",
    "print(generate_post(system_prompt, model_name, idea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55c2cd55-477e-464f-8480-f9e354fb4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete files (after fine-tuning is done)\n",
    "# client.files.delete(train_file.id)\n",
    "# client.files.delete(valid_file.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b179e-52b5-4d17-a404-3db7caf88402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb44c7-7608-4d01-bba5-6ac32047fd76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
